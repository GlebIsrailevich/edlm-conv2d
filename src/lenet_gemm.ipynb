{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "81bd97b9",
      "metadata": {},
      "source": [
        "## Im2Col + GEMM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "53613066",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53613066",
        "outputId": "bee95cd6-2d36-421a-8a5e-9ef7500d9d51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random seed set as 42\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# from torchvision.io import decode_image\n",
        "# from torchvision.models import ResNet18_Weights, resnet18\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Set the global seed for NumPy's random number generator\n",
        "seed_value = 42\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "def set_seed(seed: int = 42) -> None:\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    # When running on the CuDNN backend, two further options must be set\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    # Set a fixed value for the hash seed\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    print(f\"Random seed set as {seed}\")\n",
        "\n",
        "\n",
        "set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5EzwVoQPPsHz",
      "metadata": {
        "id": "5EzwVoQPPsHz"
      },
      "outputs": [],
      "source": [
        "from classify_single import classify_single_image, evaluate_model\n",
        "from conv2dgemm import Conv2dGEMM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "JOKZgsftQ1Dm",
      "metadata": {
        "id": "JOKZgsftQ1Dm"
      },
      "outputs": [],
      "source": [
        "class LeNet(nn.Module):\n",
        "    def __init__(self, num_classes=10, kernel_size=5):\n",
        "        super(LeNet, self).__init__()\n",
        "        self.conv1 = Conv2dGEMM(in_channels=3, out_channels=6, kernel_size=kernel_size)\n",
        "        self.conv2 = Conv2dGEMM(in_channels=6, out_channels=16, kernel_size=kernel_size)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        # x = x.view(x.shape[0], -1)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "361bb768",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "361bb768",
        "outputId": "8fe4118a-1561-40c6-8d0d-8f6091de3351"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LeNet(\n",
              "  (conv1): Conv2dGEMM()\n",
              "  (conv2): Conv2dGEMM()\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def weights_init(m):\n",
        "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "        nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
        "        if m.bias is not None:\n",
        "            nn.init.constant_(m.bias, 0)\n",
        "\n",
        "\n",
        "model = LeNet(10)\n",
        "# model.reset_params()\n",
        "model.apply(weights_init)\n",
        "\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "de9a24f1",
      "metadata": {
        "id": "de9a24f1"
      },
      "outputs": [],
      "source": [
        "import ssl\n",
        "\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        ")\n",
        "\n",
        "\n",
        "train_dataset = datasets.CIFAR10(\n",
        "    root=\"./data\", train=True, download=True, transform=transform\n",
        ")\n",
        "test_dataset = datasets.CIFAR10(\n",
        "    root=\"./data\", train=False, download=True, transform=transform\n",
        ")\n",
        "\n",
        "class_names = [\n",
        "    \"airplane\",\n",
        "    \"automobile\",\n",
        "    \"bird\",\n",
        "    \"cat\",\n",
        "    \"deer\",\n",
        "    \"dog\",\n",
        "    \"frog\",\n",
        "    \"horse\",\n",
        "    \"ship\",\n",
        "    \"truck\",\n",
        "]\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "6fd2a7e0",
      "metadata": {
        "id": "6fd2a7e0"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "num_epochs = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cc24b67",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cc24b67",
        "outputId": "c6ab4105-eaf9-4ebd-95e8-ea97db543b40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10] Loss: 1.7730, Acc: 34.70%, Fwd: 3.90 ms (21.51 MB), Bwd: 1.62 ms (62.54 MB), Peak: 41.20 MB\n",
            "Epoch [2/10] Loss: 1.5164, Acc: 44.51%, Fwd: 3.47 ms (21.50 MB), Bwd: 1.42 ms (62.39 MB), Peak: 41.20 MB\n",
            "Epoch [3/10] Loss: 1.4357, Acc: 47.96%, Fwd: 3.47 ms (21.50 MB), Bwd: 1.43 ms (62.39 MB), Peak: 41.20 MB\n",
            "Epoch [4/10] Loss: 1.3740, Acc: 50.59%, Fwd: 3.47 ms (21.50 MB), Bwd: 1.45 ms (62.39 MB), Peak: 41.20 MB\n",
            "Epoch [5/10] Loss: 1.3300, Acc: 52.27%, Fwd: 3.47 ms (21.50 MB), Bwd: 1.41 ms (62.39 MB), Peak: 41.20 MB\n",
            "Epoch [6/10] Loss: 1.2957, Acc: 53.70%, Fwd: 3.47 ms (21.50 MB), Bwd: 1.40 ms (62.39 MB), Peak: 41.20 MB\n",
            "Epoch [7/10] Loss: 1.2508, Acc: 55.26%, Fwd: 3.47 ms (21.50 MB), Bwd: 1.43 ms (62.39 MB), Peak: 41.20 MB\n",
            "Epoch [8/10] Loss: 1.2316, Acc: 55.77%, Fwd: 3.46 ms (21.50 MB), Bwd: 1.41 ms (62.39 MB), Peak: 41.20 MB\n",
            "Epoch [9/10] Loss: 1.2015, Acc: 56.92%, Fwd: 3.47 ms (21.50 MB), Bwd: 1.41 ms (62.39 MB), Peak: 41.20 MB\n",
            "Epoch [10/10] Loss: 1.1713, Acc: 58.22%, Fwd: 3.61 ms (21.50 MB), Bwd: 1.56 ms (62.39 MB), Peak: 41.20 MB\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "model.train()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    total_forward_time = 0.0\n",
        "    total_backward_time = 0.0\n",
        "    total_forward_memory = 0.0\n",
        "    total_backward_memory = 0.0\n",
        "\n",
        "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        torch.cuda.reset_peak_memory_stats()\n",
        "\n",
        "        # ------- FORWARD -------\n",
        "        torch.cuda.synchronize()\n",
        "        mem_before_forward = torch.cuda.memory_allocated()\n",
        "\n",
        "        forward_start = time.perf_counter()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        torch.cuda.synchronize()\n",
        "        forward_end = time.perf_counter()\n",
        "\n",
        "        forward_time = forward_end - forward_start\n",
        "        total_forward_time += forward_time\n",
        "\n",
        "        mem_after_forward = torch.cuda.memory_allocated()\n",
        "        forward_memory = (mem_after_forward - mem_before_forward) / 1024**2\n",
        "        total_forward_memory += forward_memory\n",
        "\n",
        "        # ------- BACKWARD -------\n",
        "        torch.cuda.synchronize()\n",
        "\n",
        "        # reset peak memory stats for isolated backward measurement\n",
        "        torch.cuda.reset_peak_memory_stats()\n",
        "\n",
        "        backward_start = time.perf_counter()\n",
        "        loss.backward()\n",
        "        torch.cuda.synchronize()\n",
        "        backward_end = time.perf_counter()\n",
        "\n",
        "        backward_time = backward_end - backward_start\n",
        "        total_backward_time += backward_time\n",
        "\n",
        "        # peak memory used inside backward\n",
        "        backward_peak = torch.cuda.max_memory_allocated() / 1024**2\n",
        "        total_backward_memory += backward_peak\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        # stats\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    # epoch metrics\n",
        "    avg_forward = total_forward_time / len(train_loader)\n",
        "    avg_backward = total_backward_time / len(train_loader)\n",
        "    avg_forward_mem = total_forward_memory / len(train_loader)\n",
        "    avg_backward_mem = total_backward_memory / len(train_loader)\n",
        "    peak_memory = torch.cuda.max_memory_allocated() / 1024**2\n",
        "\n",
        "    print(\n",
        "        f\"Epoch [{epoch + 1}/{num_epochs}] \"\n",
        "        f\"Loss: {running_loss / len(train_loader):.4f}, \"\n",
        "        f\"Acc: {100 * correct / total:.2f}%, \"\n",
        "        f\"Fwd: {avg_forward * 1000:.2f} ms ({avg_forward_mem:.2f} MB), \"\n",
        "        f\"Bwd: {avg_backward * 1000:.2f} ms ({avg_backward_mem:.2f} MB), \"\n",
        "        f\"Peak: {peak_memory:.2f} MB\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NmZA8ABUMsXK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmZA8ABUMsXK",
        "outputId": "f2d7eda9-bc35-452d-cf79-3df89351b508"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 53.16%\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "acc = evaluate_model(model, test_loader, device)\n",
        "report = {\n",
        "    \"name\": \"lenet\",\n",
        "    \"batch_size\": 64,\n",
        "    \"avg_forward\": avg_forward,\n",
        "    \"avg_backward\": avg_backward,\n",
        "    \"avg_forward_mem\": avg_forward_mem,\n",
        "    \"avg_backward_mem\": avg_backward_mem,\n",
        "    \"kernel_size\": 5,\n",
        "    \"acc\": acc,\n",
        "}\n",
        "\n",
        "file_path = \"lenetgemm_kernel5_bs64.json\"\n",
        "\n",
        "with open(file_path, \"w\") as f:\n",
        "    json.dump(report, f, indent=4)  # indent=4 makes the JSON file human-readable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0608bb2c",
      "metadata": {
        "id": "0608bb2c"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((32, 32)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "image = Image.open(\"/content/cat_watermelon.jpg\").convert(\"RGB\")\n",
        "sample_image = transform(image).unsqueeze(0).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b651dfc8",
      "metadata": {
        "id": "b651dfc8"
      },
      "outputs": [],
      "source": [
        "from torch.profiler import ProfilerActivity, profile\n",
        "\n",
        "\n",
        "def on_trace_ready(prof):\n",
        "    prof.export_chrome_trace(\"trace.json\")\n",
        "\n",
        "\n",
        "with profile(\n",
        "    activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
        "    on_trace_ready=on_trace_ready,\n",
        ") as prof:\n",
        "    # batch = preprocess(img).unsqueeze(0)\n",
        "\n",
        "    # # Step 4: Use the model and print the predicted category\n",
        "    # prediction = model(batch).squeeze(0).softmax(0)\n",
        "    # class_id = prediction.argmax().item()\n",
        "    # score = prediction[class_id].item()\n",
        "    # category_name = weights.meta[\"categories\"][class_id]\n",
        "    classify_single_image(model, sample_image, device, class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "ce6f7acc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce6f7acc",
        "outputId": "3b7650bd-b477-4cfb-ee5e-dc6e90ff92e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                           aten::linear         0.08%      21.098us        63.76%      17.299ms       5.766ms       0.000us         0.00%      50.398us      16.799us             3  \n",
            "                                            aten::addmm        14.83%       4.022ms        63.59%      17.253ms       5.751ms      19.743us        10.44%      50.398us      16.799us             3  \n",
            "                                           aten::im2col         4.89%       1.327ms         5.98%       1.623ms     811.324us      38.815us        20.53%      49.087us      24.543us             2  \n",
            "                                           aten::matmul         0.10%      27.023us         3.99%       1.082ms     541.097us       0.000us         0.00%      45.792us      22.896us             2  \n",
            "                                               aten::mm         0.58%     156.434us         3.79%       1.028ms     514.066us      30.880us        16.33%      45.792us      22.896us             2  \n",
            "void at::native::im2col_kernel<float>(long, float co...         0.00%       0.000us         0.00%       0.000us       0.000us      38.815us        20.53%      38.815us      19.408us             2  \n",
            "                                       aten::max_pool2d         0.03%       9.158us         0.24%      64.667us      32.334us       0.000us         0.00%      35.550us      17.775us             2  \n",
            "                          aten::max_pool2d_with_indices         0.14%      38.463us         0.20%      55.509us      27.755us      35.550us        18.80%      35.550us      17.775us             2  \n",
            "void at::native::(anonymous namespace)::max_pool_for...         0.00%       0.000us         0.00%       0.000us       0.000us      35.550us        18.80%      35.550us      17.775us             2  \n",
            "                                  Lazy Function Loading         0.55%     149.675us         0.55%     149.675us      37.419us      32.799us        17.35%      32.799us       8.200us             4  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 27.130ms\n",
            "Self CUDA time total: 189.082us\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "oEf9F7HMNJaE",
      "metadata": {
        "id": "oEf9F7HMNJaE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "Yz1uMGqoUC2o",
      "metadata": {
        "id": "Yz1uMGqoUC2o"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
