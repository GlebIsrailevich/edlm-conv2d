{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a17b8a54",
      "metadata": {},
      "source": [
        "## Структурная   Спарсификация (filter/channel wise)\n",
        "\n",
        "- сначала применяем свертку к фильтрам затем к каналам\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ce4d219d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce4d219d",
        "outputId": "2a36ec0f-ad42-43c2-ee31-130e4057b212"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random seed set as 42\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# from torchvision.io import decode_image\n",
        "# from torchvision.models import ResNet18_Weights, resnet18\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Set the global seed for NumPy's random number generator\n",
        "seed_value = 42\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "def set_seed(seed: int = 42) -> None:\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    # When running on the CuDNN backend, two further options must be set\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    # Set a fixed value for the hash seed\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    print(f\"Random seed set as {seed}\")\n",
        "\n",
        "\n",
        "set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca30440f",
      "metadata": {
        "id": "ca30440f"
      },
      "outputs": [],
      "source": [
        "from structural_sparsification import StructuredSConv\n",
        "from classify_single import evaluate_model, classify_single_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23b24608",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23b24608",
        "outputId": "c1217f96-f740-47af-ac14-a694efe41e41"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SparseLeNet(\n",
              "  (conv1): StructuredSConv(\n",
              "    (s_filter): StructuredSparsifier()\n",
              "    (s_channel): StructuredSparsifier()\n",
              "  )\n",
              "  (conv2): StructuredSConv(\n",
              "    (s_filter): StructuredSparsifier()\n",
              "    (s_channel): StructuredSparsifier()\n",
              "  )\n",
              "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class SparseLeNet(nn.Module):\n",
        "    def __init__(self, sparsity_ratio=0.7):\n",
        "        super().__init__()\n",
        "        self.conv1 = StructuredSConv(\n",
        "            sparsity_ratio,\n",
        "            in_channels=3,\n",
        "            out_channels=6,\n",
        "            kernel_size=5,\n",
        "        )\n",
        "        self.conv2 = StructuredSConv(\n",
        "            sparsity_ratio, in_channels=6, out_channels=16, kernel_size=5\n",
        "        )\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def weights_init(m):\n",
        "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "        nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
        "        if m.bias is not None:\n",
        "            nn.init.constant_(m.bias, 0)\n",
        "\n",
        "\n",
        "model = SparseLeNet(0.8)\n",
        "model.apply(weights_init)\n",
        "model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f15f3ecd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f15f3ecd",
        "outputId": "73a97091-1a73-48b4-9e8a-8df5156bc4b0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170M/170M [00:04<00:00, 42.5MB/s]\n"
          ]
        }
      ],
      "source": [
        "import ssl\n",
        "\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        ")\n",
        "\n",
        "\n",
        "train_dataset = datasets.CIFAR10(\n",
        "    root=\"./data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform,\n",
        ")\n",
        "test_dataset = datasets.CIFAR10(\n",
        "    root=\"./data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform,\n",
        ")\n",
        "\n",
        "class_names = [\n",
        "    \"airplane\",\n",
        "    \"automobile\",\n",
        "    \"bird\",\n",
        "    \"cat\",\n",
        "    \"deer\",\n",
        "    \"dog\",\n",
        "    \"frog\",\n",
        "    \"horse\",\n",
        "    \"ship\",\n",
        "    \"truck\",\n",
        "]\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "77b42a15",
      "metadata": {
        "id": "77b42a15"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "num_epochs = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bb33f53",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bb33f53",
        "outputId": "c8597ed0-a44d-4dd2-8a87-98bde1b4a12e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10] Loss: 2.3030, Acc: 9.80%, Fwd: 2.42 ms (2.78 MB), Bwd: 2.64 ms (25.11 MB), Peak: 20.75 MB\n",
            "Epoch [2/10] Loss: 2.3031, Acc: 9.98%, Fwd: 1.06 ms (2.77 MB), Bwd: 2.53 ms (25.11 MB), Peak: 20.75 MB\n",
            "Epoch [3/10] Loss: 2.3030, Acc: 9.99%, Fwd: 1.00 ms (2.77 MB), Bwd: 2.46 ms (25.11 MB), Peak: 20.75 MB\n",
            "Epoch [4/10] Loss: 2.3030, Acc: 9.82%, Fwd: 1.03 ms (2.77 MB), Bwd: 2.48 ms (25.11 MB), Peak: 20.75 MB\n",
            "Epoch [5/10] Loss: 2.3031, Acc: 9.82%, Fwd: 1.02 ms (2.77 MB), Bwd: 2.46 ms (25.11 MB), Peak: 20.75 MB\n",
            "Epoch [6/10] Loss: 2.3030, Acc: 9.88%, Fwd: 1.01 ms (2.77 MB), Bwd: 2.47 ms (25.11 MB), Peak: 20.75 MB\n",
            "Epoch [7/10] Loss: 2.3030, Acc: 9.70%, Fwd: 1.00 ms (2.77 MB), Bwd: 2.46 ms (25.11 MB), Peak: 20.75 MB\n",
            "Epoch [8/10] Loss: 2.3030, Acc: 9.85%, Fwd: 1.02 ms (2.77 MB), Bwd: 2.46 ms (25.11 MB), Peak: 20.75 MB\n",
            "Epoch [9/10] Loss: 2.3030, Acc: 9.92%, Fwd: 0.99 ms (2.77 MB), Bwd: 2.45 ms (25.11 MB), Peak: 20.75 MB\n",
            "Epoch [10/10] Loss: 2.3030, Acc: 10.06%, Fwd: 0.97 ms (2.77 MB), Bwd: 2.43 ms (25.11 MB), Peak: 20.75 MB\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "model.train()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    total_forward_time = 0.0\n",
        "    total_backward_time = 0.0\n",
        "    total_forward_memory = 0.0\n",
        "    total_backward_memory = 0.0\n",
        "\n",
        "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        torch.cuda.reset_peak_memory_stats()\n",
        "\n",
        "        torch.cuda.synchronize()\n",
        "        mem_before_forward = torch.cuda.memory_allocated()\n",
        "\n",
        "        forward_start = time.perf_counter()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        torch.cuda.synchronize()\n",
        "        forward_end = time.perf_counter()\n",
        "\n",
        "        forward_time = forward_end - forward_start\n",
        "        total_forward_time += forward_time\n",
        "\n",
        "        mem_after_forward = torch.cuda.memory_allocated()\n",
        "        forward_memory = (mem_after_forward - mem_before_forward) / 1024**2\n",
        "        total_forward_memory += forward_memory\n",
        "\n",
        "        torch.cuda.synchronize()\n",
        "\n",
        "        # reset peak memory stats for isolated backward measurement\n",
        "        torch.cuda.reset_peak_memory_stats()\n",
        "\n",
        "        backward_start = time.perf_counter()\n",
        "        loss.backward()\n",
        "        torch.cuda.synchronize()\n",
        "        backward_end = time.perf_counter()\n",
        "\n",
        "        backward_time = backward_end - backward_start\n",
        "        total_backward_time += backward_time\n",
        "\n",
        "        # peak memory used inside backward\n",
        "        backward_peak = torch.cuda.max_memory_allocated() / 1024**2\n",
        "        total_backward_memory += backward_peak\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        # stats\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    # epoch metrics\n",
        "    avg_forward = total_forward_time / len(train_loader)\n",
        "    avg_backward = total_backward_time / len(train_loader)\n",
        "    avg_forward_mem = total_forward_memory / len(train_loader)\n",
        "    avg_backward_mem = total_backward_memory / len(train_loader)\n",
        "    peak_memory = torch.cuda.max_memory_allocated() / 1024**2\n",
        "\n",
        "    print(\n",
        "        f\"Epoch [{epoch + 1}/{num_epochs}] \"\n",
        "        f\"Loss: {running_loss / len(train_loader):.4f}, \"\n",
        "        f\"Acc: {100 * correct / total:.2f}%, \"\n",
        "        f\"Fwd: {avg_forward * 1000:.2f} ms ({avg_forward_mem:.2f} MB), \"\n",
        "        f\"Bwd: {avg_backward * 1000:.2f} ms ({avg_backward_mem:.2f} MB), \"\n",
        "        f\"Peak: {peak_memory:.2f} MB\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8db0037",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8db0037",
        "outputId": "e082ead3-a4c0-4447-f3ac-f41aea7f7954"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 10.00%\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "acc = evaluate_model(model, test_loader, device)\n",
        "\n",
        "report = {\n",
        "    \"name\": \"sparse_struct_lenet_kernel7_bs8\",\n",
        "    \"batch_size\": 64,\n",
        "    \"avg_forward\": avg_forward,\n",
        "    \"avg_backward\": avg_backward,\n",
        "    \"avg_forward_mem\": avg_forward_mem,\n",
        "    \"avg_backward_mem\": avg_backward_mem,\n",
        "    \"kernel_size\": 5,\n",
        "    \"acc\": acc,\n",
        "}\n",
        "\n",
        "file_path = \"sparse_struct_lenet_kernel7_bs4.json\"\n",
        "\n",
        "with open(file_path, \"w\") as f:\n",
        "    json.dump(report, f, indent=4)  # indent=4 makes the JSON file human-readable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a993e77",
      "metadata": {
        "id": "3a993e77"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((32, 32)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "image = Image.open(\"/content/cat_watermelon.jpg\").convert(\"RGB\")\n",
        "sample_image = transform(image).unsqueeze(0).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "91d692c2",
      "metadata": {
        "id": "91d692c2"
      },
      "outputs": [],
      "source": [
        "# torch.save(model.state_dict(), \"lenet_cifar10_img2col_sparse.pth\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "97ddb18f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97ddb18f",
        "outputId": "16115308-0992-4911-d03b-c784662cd8ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                           aten::conv2d         0.03%       9.115us        14.04%       4.022ms       2.011ms       0.000us         0.00%      53.022us      26.511us             2  \n",
            "                                      aten::convolution         0.06%      16.329us        14.01%       4.013ms       2.007ms       0.000us         0.00%      53.022us      26.511us             2  \n",
            "                                     aten::_convolution         2.42%     693.744us        13.95%       3.997ms       1.998ms       0.000us         0.00%      53.022us      26.511us             2  \n",
            "                                           aten::linear         0.08%      21.808us        62.07%      17.778ms       5.926ms       0.000us         0.00%      49.918us      16.639us             3  \n",
            "                                            aten::addmm        11.79%       3.378ms        61.45%      17.599ms       5.866ms      19.615us        10.15%      49.918us      16.639us             3  \n",
            "                                aten::cudnn_convolution         8.21%       2.352ms        11.19%       3.205ms       1.602ms      44.062us        22.81%      44.062us      22.031us             2  \n",
            "void implicit_convolve_sgemm<float, float, 128, 5, 5...         0.00%       0.000us         0.00%       0.000us       0.000us      44.062us        22.81%      44.062us      22.031us             2  \n",
            "cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFla...         2.88%     824.255us        52.29%      14.978ms       1.152ms       0.000us         0.00%      30.303us       2.331us            13  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      24.959us        12.92%      24.959us       3.120us             8  \n",
            "                                              aten::mul         0.19%      54.283us         0.29%      82.040us      20.510us      18.367us         9.51%      18.367us       4.592us             4  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 28.642ms\n",
            "Self CUDA time total: 193.209us\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from torch.profiler import ProfilerActivity, profile\n",
        "\n",
        "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA]) as prof:\n",
        "    classify_single_image(model, sample_image, device, class_names)\n",
        "\n",
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "3621e90d",
      "metadata": {
        "id": "3621e90d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "0cb755ab",
      "metadata": {
        "id": "0cb755ab"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
