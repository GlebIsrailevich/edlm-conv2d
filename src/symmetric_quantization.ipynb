{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9692c622",
      "metadata": {},
      "source": [
        "## LSQ \n",
        "- Симметричная квантизация\n",
        "- один параметр квантизации для активаций другой для весов\n",
        "- симулируем эффект квантизации при точности флотов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "673ddde8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "673ddde8",
        "outputId": "1407abef-b0d2-4193-ed1b-d6cc1004465e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random seed set as 42\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# from torchvision.io import decode_image\n",
        "# from torchvision.models import ResNet18_Weights, resnet18\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Set the global seed for NumPy's random number generator\n",
        "seed_value = 42\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "def set_seed(seed: int = 42) -> None:\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    # When running on the CuDNN backend, two further options must be set\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    # Set a fixed value for the hash seed\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    print(f\"Random seed set as {seed}\")\n",
        "\n",
        "\n",
        "set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58714937",
      "metadata": {},
      "outputs": [],
      "source": [
        "from lsq_quantization import QConvImg2Col\n",
        "from classify_single import evaluate_model, classify_single_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a95ea6e7",
      "metadata": {
        "id": "a95ea6e7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c72952d",
      "metadata": {
        "id": "4c72952d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "64625733",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64625733",
        "outputId": "0fe17983-3d03-4e20-c32d-1dea49f4eb23"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LeNetIMCol(\n",
              "  (conv1): QConvImg2Col(\n",
              "    (q_act): Quantizer()\n",
              "    (q_w): Quantizer()\n",
              "  )\n",
              "  (conv2): QConvImg2Col(\n",
              "    (q_act): Quantizer()\n",
              "    (q_w): Quantizer()\n",
              "  )\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc1): Linear(in_features=144, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class LeNetIMCol(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(LeNetIMCol, self).__init__()\n",
        "        self.conv1 = QConvImg2Col(8, 3, 6, 7)\n",
        "        self.conv2 = QConvImg2Col(8, 6, 16, 7)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # final feature map after conv/pool:\n",
        "        # input 32×32 → conv5 → 28×28 → pool → 14×14\n",
        "        # → conv5 → 10×10 → pool → 5×5 → 16 channels\n",
        "        self.fc1 = nn.Linear(16 * 3 * 3, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        return self.fc3(x)\n",
        "\n",
        "\n",
        "def weights_init(m):\n",
        "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "        nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
        "        if m.bias is not None:\n",
        "            nn.init.constant_(m.bias, 0)\n",
        "\n",
        "\n",
        "model = LeNetIMCol(10)\n",
        "model.apply(weights_init)\n",
        "model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7336f7f9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7336f7f9",
        "outputId": "3c12b45b-e7f5-407e-a0cd-aae12cd41614"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170M/170M [00:03<00:00, 47.7MB/s]\n"
          ]
        }
      ],
      "source": [
        "import ssl\n",
        "\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        ")\n",
        "\n",
        "\n",
        "train_dataset = datasets.CIFAR10(\n",
        "    root=\"./data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform,\n",
        ")\n",
        "test_dataset = datasets.CIFAR10(\n",
        "    root=\"./data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform,\n",
        ")\n",
        "\n",
        "class_names = [\n",
        "    \"airplane\",\n",
        "    \"automobile\",\n",
        "    \"bird\",\n",
        "    \"cat\",\n",
        "    \"deer\",\n",
        "    \"dog\",\n",
        "    \"frog\",\n",
        "    \"horse\",\n",
        "    \"ship\",\n",
        "    \"truck\",\n",
        "]\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "0094d6bf",
      "metadata": {
        "id": "0094d6bf"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "num_epochs = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d56b7731",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d56b7731",
        "outputId": "fbaefa62-6cbf-4048-acc3-c4398e16e405"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10] Loss: 2.0774, Acc: 22.69%, Fwd: 4.94 ms (31.90 MB), Bwd: 3.39 ms (69.82 MB), Peak: 30.89 MB\n",
            "Epoch [2/10] Loss: 1.8085, Acc: 32.07%, Fwd: 4.44 ms (31.89 MB), Bwd: 3.01 ms (69.82 MB), Peak: 30.89 MB\n",
            "Epoch [3/10] Loss: 1.7183, Acc: 35.60%, Fwd: 4.45 ms (31.89 MB), Bwd: 3.03 ms (69.82 MB), Peak: 30.89 MB\n",
            "Epoch [4/10] Loss: 1.6711, Acc: 37.58%, Fwd: 4.44 ms (31.89 MB), Bwd: 3.01 ms (69.82 MB), Peak: 30.89 MB\n",
            "Epoch [5/10] Loss: 1.6276, Acc: 39.49%, Fwd: 4.46 ms (31.89 MB), Bwd: 3.04 ms (69.82 MB), Peak: 30.89 MB\n",
            "Epoch [6/10] Loss: 1.5985, Acc: 40.89%, Fwd: 4.44 ms (31.89 MB), Bwd: 3.03 ms (69.82 MB), Peak: 30.89 MB\n",
            "Epoch [7/10] Loss: 1.5705, Acc: 41.93%, Fwd: 4.45 ms (31.89 MB), Bwd: 3.04 ms (69.82 MB), Peak: 30.89 MB\n",
            "Epoch [8/10] Loss: 1.5541, Acc: 42.81%, Fwd: 4.43 ms (31.89 MB), Bwd: 3.01 ms (69.82 MB), Peak: 30.89 MB\n",
            "Epoch [9/10] Loss: 1.5311, Acc: 43.77%, Fwd: 4.45 ms (31.89 MB), Bwd: 3.06 ms (69.82 MB), Peak: 30.89 MB\n",
            "Epoch [10/10] Loss: 1.5578, Acc: 43.30%, Fwd: 4.43 ms (31.89 MB), Bwd: 3.02 ms (69.82 MB), Peak: 30.89 MB\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "model.train()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    total_forward_time = 0.0\n",
        "    total_backward_time = 0.0\n",
        "    total_forward_memory = 0.0\n",
        "    total_backward_memory = 0.0\n",
        "\n",
        "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        torch.cuda.reset_peak_memory_stats()\n",
        "\n",
        "        # ------- FORWARD -------\n",
        "        torch.cuda.synchronize()\n",
        "        mem_before_forward = torch.cuda.memory_allocated()\n",
        "\n",
        "        forward_start = time.perf_counter()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        torch.cuda.synchronize()\n",
        "        forward_end = time.perf_counter()\n",
        "\n",
        "        forward_time = forward_end - forward_start\n",
        "        total_forward_time += forward_time\n",
        "\n",
        "        mem_after_forward = torch.cuda.memory_allocated()\n",
        "        forward_memory = (mem_after_forward - mem_before_forward) / 1024**2\n",
        "        total_forward_memory += forward_memory\n",
        "\n",
        "        # ------- BACKWARD -------\n",
        "        torch.cuda.synchronize()\n",
        "\n",
        "        # reset peak memory stats for isolated backward measurement\n",
        "        torch.cuda.reset_peak_memory_stats()\n",
        "\n",
        "        backward_start = time.perf_counter()\n",
        "        loss.backward()\n",
        "        torch.cuda.synchronize()\n",
        "        backward_end = time.perf_counter()\n",
        "\n",
        "        backward_time = backward_end - backward_start\n",
        "        total_backward_time += backward_time\n",
        "\n",
        "        # peak memory used inside backward\n",
        "        backward_peak = torch.cuda.max_memory_allocated() / 1024**2\n",
        "        total_backward_memory += backward_peak\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        # stats\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    # epoch metrics\n",
        "    avg_forward = total_forward_time / len(train_loader)\n",
        "    avg_backward = total_backward_time / len(train_loader)\n",
        "    avg_forward_mem = total_forward_memory / len(train_loader)\n",
        "    avg_backward_mem = total_backward_memory / len(train_loader)\n",
        "    peak_memory = torch.cuda.max_memory_allocated() / 1024**2\n",
        "\n",
        "    print(\n",
        "        f\"Epoch [{epoch + 1}/{num_epochs}] \"\n",
        "        f\"Loss: {running_loss / len(train_loader):.4f}, \"\n",
        "        f\"Acc: {100 * correct / total:.2f}%, \"\n",
        "        f\"Fwd: {avg_forward * 1000:.2f} ms ({avg_forward_mem:.2f} MB), \"\n",
        "        f\"Bwd: {avg_backward * 1000:.2f} ms ({avg_backward_mem:.2f} MB), \"\n",
        "        f\"Peak: {peak_memory:.2f} MB\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "t91Nm07PWEbK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t91Nm07PWEbK",
        "outputId": "cb88c5c6-bc07-4735-d3ee-c84b952a15da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 43.03%\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "acc = evaluate_model(model, test_loader, device)\n",
        "report = {\n",
        "    \"name\": \"lenet_quantized\",\n",
        "    \"batch_size\": 64,\n",
        "    \"avg_forward\": avg_forward,\n",
        "    \"avg_backward\": avg_backward,\n",
        "    \"avg_forward_mem\": avg_forward_mem,\n",
        "    \"avg_backward_mem\": avg_backward_mem,\n",
        "    \"kernel_size\": 5,\n",
        "    \"acc\": acc,\n",
        "}\n",
        "\n",
        "file_path = \"lenet_quantized_kernel5_bs64.json\"\n",
        "\n",
        "with open(file_path, \"w\") as f:\n",
        "    json.dump(report, f, indent=4)  # indent=4 makes the JSON file human-readable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffe63761",
      "metadata": {
        "id": "ffe63761"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((32, 32)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "image = Image.open(\"/content/cat_watermelon.jpg\").convert(\"RGB\")\n",
        "sample_image = transform(image).unsqueeze(0).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "2fa50b5d",
      "metadata": {
        "id": "2fa50b5d"
      },
      "outputs": [],
      "source": [
        "from torch.profiler import ProfilerActivity, profile\n",
        "\n",
        "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA]) as prof:\n",
        "    # batch = preprocess(img).unsqueeze(0)\n",
        "\n",
        "    # # Step 4: Use the model and print the predicted category\n",
        "    # prediction = model(batch).squeeze(0).softmax(0)\n",
        "    # class_id = prediction.argmax().item()\n",
        "    # score = prediction[class_id].item()\n",
        "    # category_name = weights.meta[\"categories\"][class_id]\n",
        "    classify_single_image(model, sample_image, device, class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "fd708195",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd708195",
        "outputId": "87194c32-1c03-409d-bf72-021aa3686f0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                           aten::im2col         5.14%       1.471ms         5.61%       1.604ms     802.249us      54.558us        17.84%      59.902us      29.951us             2  \n",
            "void at::native::im2col_kernel<float>(long, float co...         0.00%       0.000us         0.00%       0.000us       0.000us      54.558us        17.84%      54.558us      27.279us             2  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      53.345us        17.45%      53.345us       3.334us            16  \n",
            "                                              aten::bmm         0.57%     163.318us         3.46%     990.120us     495.060us      36.383us        11.90%      36.383us      18.191us             2  \n",
            "                                           aten::linear         0.08%      22.607us        76.94%      22.016ms       7.339ms       0.000us         0.00%      35.324us      11.775us             3  \n",
            "                                            aten::addmm        16.55%       4.736ms        76.75%      21.961ms       7.320ms      17.279us         5.65%      35.324us      11.775us             3  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      30.049us         9.83%      30.049us       3.756us             8  \n",
            "                                              aten::mul         0.62%     176.411us         0.98%     281.160us      35.145us      29.280us         9.58%      29.280us       3.660us             8  \n",
            "                                              aten::sub         0.41%     115.892us         0.65%     185.629us      23.204us      27.041us         8.84%      27.041us       3.380us             8  \n",
            "                                              aten::add         0.27%      78.389us         0.45%     129.584us      16.198us      26.304us         8.60%      26.304us       3.288us             8  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 28.614ms\n",
            "Self CUDA time total: 305.757us\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "5908c0ec",
      "metadata": {
        "id": "5908c0ec"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
